
# ClinIQ â€“ GenAI-Powered Medical Lab Report Analyzer

ClinIQ is a full-stack, production-ready GenAI application that:
- ğŸ§¾ Extracts text from scanned PDF lab reports (CBC, Hematology, Urine, etc.)
- ğŸ§  Retrieves contextual medical knowledge from a custom ChromaDB vector store
- ğŸ§¬ Generates intelligent summaries using local LLaMA-based models via [Ollama](https://ollama.com/)
- âœ… Supports concurrent users with Celery + Redis task queue
- ğŸ§ª Includes test cases, monitoring logs, and evaluation utilities

---

## Project Structure

```
ClinIQ/
â”œâ”€â”€ app.py                 # Main Flask app
â”œâ”€â”€ celery_worker.py       # Celery task runner
â”œâ”€â”€ backend/               # Core logic: OCR, summary, retrieval
â”œâ”€â”€ api/                   # Ollama interface
â”œâ”€â”€ templates/             # HTML templates (index, loading, error)
â”œâ”€â”€ static/                # CSS styles, loader
â”œâ”€â”€ logs/                  # Output and error logs
â”œâ”€â”€ config/                # App config, settings
â”œâ”€â”€ data/                  # Sample reports and medical knowledge
â”œâ”€â”€ Dockerfile             # Production-ready container
â”œâ”€â”€ docker-compose.yaml    # Services: Flask, Celery, Redis
â”œâ”€â”€ requirements.txt       # Python packages
â””â”€â”€ README.md              # This file
```
---
## To Do:

* P0 - Evaluation and Monitoring
* P1 - Tests
* P2 - Add confidence levels or flags (green/yellow/red) to indicate summary quality based on extracted text and context.

---

## Quick Start (Local, No Docker)

### 1. Clone the Repo & Create Environment

```bash
git clone https://github.com/your-username/cliniq.git
cd cliniq

conda create -f environment.yaml
```
or

```bash
conda create -n cliniq python=3.10 -y
conda activate cliniq
pip install -r requirements.txt 
```

### 2. Install System Packages

> Required for OCR:
```bash
brew install tesseract    # macOS
sudo apt install tesseract-ocr  # Ubuntu
```

### 3. Run Redis Locally (optional)

```bash
redis-server
```

(Or use Docker: `docker run -p 6379:6379 redis`)

### 4. Run Ollama with LLaMA

```bash
ollama run llama3
```

> Download and preload the model (prompt: "Say hello")

### 5. Start the App

In one terminal:
```bash
python app.py
```

In another terminal:
```bash
celery -A celery_worker worker --loglevel=info
```

Now open [http://localhost:5050](http://localhost:5050)

---

## Quick Start with Docker

### 1. Build and Launch

```bash
docker compose up --build
```

This starts:
- Flask app with Gunicorn (`cliniq_app`)
- Celery worker (`cliniq_celery`)
- Redis queue (`cliniq_redis`)

> âœ… Make sure [Ollama](https://ollama.com) is running on your host:  
```bash
ollama run llama3
```

> ğŸ” Update `api/local_llm.py` to:
```python
OLLAMA_API_URL = "http://host.docker.internal:11434/api/generate"
```

---

## Testing

Run all tests using:

```bash
pytest
```

Youâ€™ll find:
- `tests/test_summary.py`
- `tests/test_ocr.py`
- `tests/test_pipeline.py`

---

## ğŸ›  Features

| Feature                  | Description |
|--------------------------|-------------|
| ğŸ“„ OCR                   | Extracts text from PDFs using Tesseract |
| ğŸ§  LLM Summarization     | Uses local LLaMA (via Ollama) |
| ğŸ“š Retrieval             | Contextual vector DB from medical knowledge |
| âš™ï¸ Async Tasks           | Celery + Redis for concurrency |
| ğŸ§ª Monitoring            | Logs performance and failures |
| ğŸ“¦ Dockerized            | Runs all services together in production |

---

## ğŸ“Œ Requirements

- Python 3.10+
- Redis
- Tesseract OCR
- Ollama (LLaMA model)
- Docker (optional)

---
